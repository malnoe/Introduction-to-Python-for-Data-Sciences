{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6513e49-b1cc-4604-b563-cf8b1809fc6a",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td width=15%><img src=\"../../img/UGA.png\"></img></td>\n",
    "<td><center><h1>Project n°1</h1></center></td>\n",
    "<td width=15%><a href=\"https://team.inria.fr/tripop/team-members/\" style=\"font-size: 16px; font-weight: bold\">Florian Vincent</a> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebed333f-332c-4de9-9ee5-ef2e980d49c5",
   "metadata": {},
   "source": [
    "# Basic numerical methods for convex optimization\n",
    "\n",
    "We will focus on this project in one very interesting problem that arises in multiple topics in data sciences: convex optimization and numerical methods.\n",
    "\n",
    "This project is adapted for students who wish to strengthen their understanding of the numpy library, and who prefer more math-leaning questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c8560-e149-4bc0-90db-764ae510c90c",
   "metadata": {},
   "source": [
    "## Overlook on the topic\n",
    "\n",
    "The main question is to minimize or maximize a given scalar function of one or multiple parameters.\n",
    "In litterature, minimization problems are studied very frequently so we shall have a closer look at their mathematical expression:\n",
    "\n",
    "Let a parameter $\\theta$ represent the parameters of the function we wish to minimize, living in its space denoted $\\Theta$. This function is usually called a \"loss function\", so we denote it by:\n",
    "$$\n",
    "\\begin{array}{rlcl}L:&\\Theta\\subseteq\\mathbb{R}^n &\\to &\\mathbb{R}\\\\ &\\theta &\\to & L(\\theta)\\end{array}\n",
    "$$\n",
    "Thus the problem writes:\n",
    "$$\n",
    "\\min_{\\theta\\in\\Theta}L(\\theta)\n",
    "$$\n",
    "\n",
    "Some mathematical background teaches us that this minimization problem may have either one, multiple, or no feasible solutions.\n",
    "\n",
    "__Examples__:\n",
    "* For $L(\\theta):=\\theta$ with $\\theta\\in\\mathbb{R}$ we have no feasible solution.\n",
    "* For $L(\\theta):=\\theta^2-\\theta$ with $\\theta\\in\\mathbb{R}$ we have one feasible optimal solution for $\\hat{\\theta}=\\frac{1}{2}$\n",
    "* For $L(\\theta):=3\\cos(2\\pi\\theta)+2$ with $\\theta\\in\\mathbb{R}$ we have an infinity of optimal solutions $\\hat{\\theta}_k=k+\\frac{1}{2}$ $\\forall k\\in\\mathbb{Z}$.\n",
    "The main point is that when $L$ is strictly convex their must be at most one solution to the problem, which simplifies tremendously the research of $\\theta$.\n",
    "\n",
    "---\n",
    "\n",
    "Multiple methods have been invented to solve the problem described earlier, depending on the conditions of optimization of the function as well as its shape and regularity.\n",
    "We will study four methods in increasing order of difficulty of implementation:\n",
    "* The classical \"gradient descent\" method. It is very general and easy to implement.\n",
    "* The second order methods like the Newton algorithm, and its most well known cousin the BFGS method.\n",
    "* The stochastic optimisation methods, and its most trending one in machine learning: the Adam algorithm.\n",
    "\n",
    "Everything studied here is related to differentiable scalar-valued functions.\n",
    "\n",
    "## Applications of this topic\n",
    "\n",
    "What you will learn about in this project is the foundation of multiple domains of data sciences:\n",
    "* Most obvious of all: machne learning in which the Adam algorithm is a center piece.\n",
    "* Operational research in which the constraints $\\Theta$ play an extra important role.\n",
    "* Finance which relies on stochastic problems very often formulated as optimisation problems.\n",
    "* Physics in which computation of minimal action can lead to surprisingly difficult optimisation formulations.\n",
    "* Statistics questions like the research of _Maximum a-posteriori_ (MAP) estimators, or _Maximum Likelihood Estimation_ (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72146a5b-0d85-4856-80cb-f84cdb1107a1",
   "metadata": {},
   "source": [
    "## Code and objectives\n",
    "\n",
    "This project needs to be done using python, and the numpy library as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a255ecef-53f2-4eac-800d-122deda81c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044a78d-8d62-4856-b1fd-17913c2d73a9",
   "metadata": {},
   "source": [
    "You will answer the questions by writting code and writing markdown comments to help your teaching staff see if every notion is well understood.\n",
    "Please note that the Jupyter notebook is only useful to __prototype the code__, not to write it all.\n",
    "Your report should contain this notebook, with a minimal amount of code added, and several python files containing the functions and classes you will make, that you can import in the notebook.\n",
    "Writting `class` and `def` statements in this notebook should be avoided as much as possible.\n",
    "\n",
    "This project is formulated such that you can use object-oriented programming (OOP) to answer the questions.\n",
    "This way, every question leads to the creation of a class that needs to be instanciated and properly commented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f494d0-8918-439f-936f-aa91b856a06d",
   "metadata": {},
   "source": [
    "We will optimize at each exercise a function deriving by inheritance from the following class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d793af-cee1-4121-b1e2-c466cfcd9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseloss import LossFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c3b66-b2dd-48fa-a335-752e5dc4e80a",
   "metadata": {},
   "source": [
    "The optimisation procedures that you will write should inherit as well from its own base class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec72cb7-4122-4def-8d48-b03e5ea51543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseoptimizer import Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3bcfa8-6931-4c4e-b571-919bdceaa9c1",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab232c38-b3ae-4e82-8e82-beafa9c44768",
   "metadata": {},
   "source": [
    "The main algorithm for the optimisation of convex functions is called gradient descent.\n",
    "Its main idea is to use the taylor expansion of the function at a starting point and to try and find a \"local\" best guess for the next one.\n",
    "Say one is evaluating the loss at the point $\\theta_0$ and wishes to find locally (and at order 1) the best theta to go to around them, they may write for all directions $\\vec{p}$ somewhat keeping us close to $\\theta_0$:\n",
    "$$\n",
    "L(\\theta_0+\\vec{p}) = L(\\theta_0) + \\left<\\vec{p} | \\nabla L(\\theta_0)\\right> + \\mathcal{O}(\\|\\vec{p}\\|^2)\n",
    "$$\n",
    "(writting $<\\cdot |\\cdot>$ the scalar product between two vectors and $\\|\\cdot\\|$ the euclidian norm, and $\\nabla$ the vector containing the partial derivatives of $L$ with respect to its parameters).\n",
    "\n",
    "Minimizing locally (i.e. forgetting purposefuly about the remainder $\\mathcal{O}(\\|\\vec{p}\\|^2)$), we can make a clever choice of $\\vec{p}$:\n",
    "$$\n",
    "p:=-\\eta\\nabla L(\\theta_0)\n",
    "$$\n",
    "with $\\eta$ very small against $\\nabla L(\\theta_0)$. This way the expansion writes:\n",
    "$$\n",
    "L(\\theta_0-\\eta\\nabla L(\\theta_0)) = L(\\theta_0) + \\left<-\\eta\\nabla L(\\theta_0) | \\nabla L(\\theta_0)\\right> + \\mathcal{O}(\\|\\eta\\nabla L(\\theta_0)\\|^2) = L(\\theta_0) - \\eta\\|\\nabla L(\\theta_0)\\|^2+\\|\\nabla L(\\theta_0)\\|^2\\mathcal{O}(\\eta^2)\n",
    "$$\n",
    "If $\\eta$ is small enough, $\\mathcal{O}(\\eta^2)$ should be significantly smaller than $\\eta$, hence $(\\eta-\\mathcal{O}(\\eta^2))\\|\\nabla L(\\theta_0)\\|^2$ should be positive.\n",
    "We conclude that we have performed a descent since $L(\\theta_0-\\eta\\nabla L(\\theta_0)) < L(\\theta_0)$ !\n",
    "This yields the algorithm of the gradient descent :\n",
    "```\n",
    "Start at theta := theta_0\n",
    "While no convergence is observed:\n",
    "    set theta_new := theta - eta * gradient_oracle(L, theta)\n",
    "    forget theta, set theta := theta_new\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac5e45-6538-4eca-ac32-36dfa1d6202c",
   "metadata": {},
   "source": [
    "**Implement gradient descent in a class called `GradientDescent`, performing on its internal parameter $\\theta$ the update described above for the function `function1` (suppose it is a convex function) starting at $\\theta_0:=\\vec{0}$. Study different values of $\\eta$, comment**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991f2839-e521-457b-8e9b-c53b2acde326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_random_func1, make_random_func2\n",
    "function1 = make_random_func1(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c891cb8c-4c3f-4b12-986b-fdb5ee111e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient :\n",
      "Nombre d'étapes : 912\n",
      "[ 1.7476622  -1.33807632  0.92071806  1.01222843  1.02037749  0.814345\n",
      "  2.2341816  -1.36803506  0.37750316 -0.61952388  0.96456833  1.28894403\n",
      "  2.34963875  1.08693058 -0.33707564  0.77803129  0.33445091 -0.02406402\n",
      "  1.37308327  0.849225   -0.27966902 -1.55100087  0.2405591  -1.78045823\n",
      "  0.40868512  0.28552223  0.47875344  0.14337488 -0.12632675  0.81310804\n",
      " -0.27857666  1.19181826 -0.95203219  0.52786692 -0.429852    1.32229822\n",
      "  0.93301985  1.56907039 -0.41477036 -1.06498058 -0.32649688 -0.3289662\n",
      "  0.22951223 -1.61319381  0.72398673  0.03051201 -0.00974057  0.92688631\n",
      " -1.2902574   0.43782717 -0.99732013  0.6121603  -1.35493642  0.02800539\n",
      " -0.72670189 -0.97429814 -0.01538653  0.179231   -0.78231775 -1.13082189\n",
      "  0.95488887  0.58333481  1.02040463  0.7153719  -0.21566757 -1.46495744\n",
      "  0.22127165 -1.47126734 -2.13154093  0.72432267  0.52764864 -0.35624879\n",
      " -1.38082046 -0.22042277  0.85810044 -0.15065071 -0.26415926 -0.19499811\n",
      "  0.93480905  1.17401274  1.84138149  0.02109155  0.97860307  1.43829017\n",
      "  0.64957266 -0.85633355  1.06891752  0.27585756 -0.96055801  0.14905222\n",
      " -0.34741373 -0.42837363 -1.31968857 -0.27766576  0.32477919  0.67992632\n",
      " -2.04407696 -0.89248754  1.0299212   0.1388087 ]\n"
     ]
    }
   ],
   "source": [
    "from projet1 import GradientDescent\n",
    "n = 100\n",
    "print(\"Gradient :\")\n",
    "res = GradientDescent(eps = 0.00001, theta0 = np.array([0 for _ in range(n)]), L=function1, eta = 0.01)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90aee68-1d83-4cba-a188-90c14438e190",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Closely related to the standard gradient descent, many have studied variation of the algorithm to account for more informations on the loss.\n",
    "\n",
    "So-called Newton methods arise when one tries to expend the Taylor expansion above to more terms:\n",
    "$$\n",
    "L(\\theta_0+\\vec{p})=L(\\theta_0)+\\left<\\vec{p}|\\nabla L(\\theta_0)\\right> + \\frac{1}{2!}\\left<\\vec{p}|\\nabla^2L(\\theta_0)\\vec{p}\\right> + \\mathcal{O}(\\|\\vec{p}\\|^3)\n",
    "$$\n",
    "where $\\nabla^2$ denotes the hessian of the loss, i.e. its second order derivatives.\n",
    "Note that since we study a scalar-valued loss, the gradient is a vector and the hessian is a matrix.\n",
    "\n",
    "To solve this, the Newton method uses the information from the hessian by updating $\\vec{p}$ with the inverse of the hessian:\n",
    "$$\n",
    "\\vec{p}:=-\\eta\\nabla^{\\textbf{-2}}L(\\theta_0)\\nabla L(\\theta_0)\n",
    "$$\n",
    "This formula stems from the local minimization of the Taylor expansion. To see that, take the gradient of the top equation with respect to $\\vec{p}$ and make it null (this is a classical optimality condition result, the minimum is achieved where the gradient is null):\n",
    "$$\n",
    "\\begin{array}{ll}&\\nabla L(\\theta_0)+\\nabla^2L(\\theta_0)\\vec{p}=\\vec{0}\\\\ \\therefore & \\vec{p}:=-\\nabla^{\\textbf{-2}}L(\\theta_0)\\nabla L(\\theta_0)\\end{array}\n",
    "$$\n",
    "Notice how the \"learning rate\" has disapeared and the inverse hessian somehow \"took its place\".\n",
    "\n",
    "**Implement the Newton method as `NewtonDescentNaive` starting at $\\theta_0:=\\vec{0}$, using the `hessian_oracle` method of `function2` (suppose it is a convex twice-differentiable function) to get its hessian. You will use the invert of the hessian, noted $\\nabla^{-2}L$ in the above equation, to perform the step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339db7be-0947-411d-a42e-350a69109b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function2 = make_random_func1(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c64ccf-2db1-427f-ac88-e6d20f46b346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewtonNaive :\n",
      "Nombre d'étapes : 3\n",
      "[-0.12493507 -0.90947735  0.24527842 -0.25615948 -0.71687596  0.47428117\n",
      " -1.27681174  1.1373095   0.45810611 -0.04897727]\n"
     ]
    }
   ],
   "source": [
    "from projet1 import NewtonDescentNaive\n",
    "n=10\n",
    "print(\"NewtonNaive :\")\n",
    "res = NewtonDescentNaive(eps = 0.0001, theta0 = np.array([0 for _ in range(n)]), L=function2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c425c2ca-7ee5-434b-bfc4-bc4ca7d02160",
   "metadata": {},
   "source": [
    "**Try to make a new version of this solver, `NewtonDescentClever`, which solves the linear system of equations $-\\eta\\nabla^2L(\\theta_0)\\vec{p}=\\nabla L(\\theta_0)$ at each step.\n",
    "Measure the difference in computing time on `function3`.\n",
    "How many iterations does it need?\n",
    "Knowing that the mystery function that you optimize is $L(\\theta)=\\frac{1}{2}\\theta^TA\\theta+b\\theta$ with $A$ an spd matrixKnowing that the mystery function that you optimize is $L(\\theta)=\\frac{1}{2}\\theta^TA\\theta+b\\theta$ with $A$ an spd matrix, can you explain this performance? Would it be the same for another function?**, can you explain this performance? Would it be the same for another function?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe124419-ec68-472b-929e-3c8c2c4bf257",
   "metadata": {},
   "outputs": [],
   "source": [
    "function3 = make_random_func1(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d77fcafc-125e-4cdb-992a-2c566d5594f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescentClever :\n",
      "[-0.48059211 -0.45073331  0.13964427  1.38644847 -1.4660605   0.04363138\n",
      "  0.02760145  0.56216066  1.16581146  0.43905158]\n"
     ]
    }
   ],
   "source": [
    "from projet1 import NewtonDescentClever\n",
    "n=10\n",
    "print(\"DescentClever :\")\n",
    "res = NewtonDescentClever(theta0 = np.array([0 for _ in range(n)]), L=function3)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e27c3-0601-40e8-a30a-bc7ec4e057e0",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Usualy, the hessian itself is not available to the user, so one may wish to find good approximates for Newton methods.\n",
    "This yields so-called Quasi-Newton methods.\n",
    "\n",
    "The most used are all the BFGS methods (standing for \"Broyden–Fletcher–Goldfarb–Shanno\").\n",
    "\n",
    "The main idea is to update the estimation of the inverse hessian by a low-rank matrix (it should span few dimensions, here 2).\n",
    "\n",
    "This update matrix is described as a weighted sum of:\n",
    "* a projector for the change of gradient $y:=\\nabla L(\\theta_1) - \\nabla L(\\theta_0)$ which as a rank-one matrix is proportional to $yy^T$\n",
    "* a projector for the Newtonian system of equations $s_b:=\\nabla^{-2}L(\\theta_1)(\\theta_1-\\theta_0)$ which as a rank-one matrix is proportional to $s_bs_b^T$. We note $s_b=\\nabla^{-2}L(\\theta_1)s$ with $s$ the change of parameters.\n",
    "\n",
    "The update rule then writes, for $B$ a local approximation of $\\nabla^{-2}L$, noting the outer product $a\\otimes b:=ab^T$ for vectors:\n",
    "$$\n",
    "B_k = B_{k-1} + \\frac{y\\otimes y}{<y|s>} - \\frac{s_b\\otimes s_b}{<s|s_b>}\n",
    "$$\n",
    "\n",
    "The advantage is that the algorithm does not need to invert a full rank system.\n",
    "\n",
    "Here is the algorithm:\n",
    "```\n",
    "Start at:\n",
    "    theta := theta_0\n",
    "    B := Id\n",
    "    grad := gradient_oracle(theta_0)\n",
    "Perform a normal gradient step on theta\n",
    "\n",
    "While no convergence observed:\n",
    "    Set grad_new at gradient_oracle(theta)\n",
    "    Set theta_new to theta - eta * matrix_product( B , grad )\n",
    "    Compute s = theta_new - theta\n",
    "    Compute y = grad_new - grad\n",
    "    Set B_new = B + outer( y , y ) / inner( y , s ) - outer( Bs , Bs ) / inner( s , Bs )\n",
    "    Forget last B, y, s, theta and grad \n",
    "```\n",
    "\n",
    "**Implement the BFGS algorithm in a new `BfgsDescent` class, and test it on the function `function4`. Warning: do NOT use the hessian oracle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d239254-ae90-4244-9e16-0b419be746a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "function4 = make_random_func1(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20dde71f-5015-464c-bd94-d4e93113f819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'étapes : 70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.92008285, -1.21271317, -1.4882108 ,  0.91791047, -0.68102316,\n",
       "        0.33149933,  1.45079409, -1.92952691, -0.69117778,  1.30177288])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from projet1 import BfgsDescent\n",
    "BfgsDescent(eps=0.0001, theta0=np.array([0 for _ in range(10)]), L=function4, eta=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599155d6-dc35-4a3a-97d7-99b9c75cccd6",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "To close the loop, we will study a significantly different kind of problem: the stochastic optimisation.\n",
    "\n",
    "They are way more frequent than deterministic algorithms since a lot of real world applications tackle with the randomness of some data experiments.\n",
    "They are formulated as follows:\n",
    "$$\n",
    "\\min_{\\theta\\in\\Theta}\\underbrace{\\mathbb{E}_{X\\sim\\mathbb{P}}\\left[J_\\theta(X)\\right]}_{:=L(\\theta)}\n",
    "$$\n",
    "\n",
    "We suppose that in a general case, $X$ being observed data vectors, we lack an access to the real data distribution $\\mathbb{P}$.\n",
    "So we cannot sample arbitrarily from $P$ and must design clever algorithm that take care of the complexity of the number of samples that we draw from the distribution $P$.\n",
    "\n",
    "The first idea could be to draw a finite amount of samples $X_0, \\dots, X_N$ for $N$ large enough and perform a monte carlo strategy:\n",
    "$$\n",
    "\\nabla L(\\theta_0)=\\nabla\\left.\\mathbb{E}_{i\\in \\{0\\dots N\\}}\\left[J_\\theta(X_i)\\right]\\right|_{\\theta=\\theta_0}\n",
    "$$\n",
    "\n",
    "Taking directly the gradient of the expectation is not easy theoreticaly, but since the sampling is independent of $\\theta$ (i.e. $\\mathbb{P}\\perp\\theta$), we may exchange $\\mathbb{E}$ and $\\nabla$ and get a good estimate since both operators are linear in different variables:\n",
    "$$\n",
    "\\nabla L(\\theta_0)=\\mathbb{E}_{i\\in \\{0\\dots N\\}}\\left[\\nabla_\\theta\\left.J_\\theta(X_i)\\right|_{\\theta=\\theta_0}\\right]\n",
    "$$\n",
    "This helps understand the relevance of what are called *stochastic gradient descent* (SGD) algorithms which use the gradient oracle for $J$ (instead of $L$ which we cannot access easily):\n",
    "\n",
    "```\n",
    "Start at theta := theta_0\n",
    "While no convergence observed:\n",
    "    Sample a data point X from the distribution\n",
    "    Compute randomized_grad := gradient_oracle( X , theta )\n",
    "    Set theta_new := theta - eta * randomized_grad\n",
    "```\n",
    "\n",
    "One may also use a batched version:\n",
    "```\n",
    "Start at theta := theta_0\n",
    "While no convergence observed:\n",
    "    Sample m+1 data point X_0, ..., X_m from the distribution\n",
    "    Compute batch_grad := gradient_oracle( X_0 , ... , X_m , theta ) as the empirical mean on m+1 data points\n",
    "    Set theta_new := theta - eta * batch_grad\n",
    "```\n",
    "**Implement in the class `StochasticDescent` the minibatch version (for a batchsize of 1, i.e. the first algorithm) for the stochastic loss `function5`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "352e4099-e6dc-4811-8ddc-112c8c8769f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_random_func2\n",
    "function5 = make_random_func2(10000, 10) # Same problem size, 10, but data may be too much for batch descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37fea9c-801b-4209-a340-1fe5eb61a41a",
   "metadata": {},
   "source": [
    "In the machine learning cmmunity, the optimisation problems may not be convex, they may have saddle point (the hessian is non-invertible so the algorithm is stuck) or be highly stochastic.\n",
    "The distribution $\\mathbb{P}$ may be populated by a very high amount of samples as well.\n",
    "\n",
    "\n",
    "So stochastic algorithm had to be improved in several ways.\n",
    "The first good idea came (mostly) from Pr. Nesterov, it is the addition of a \"momentum\" in the gradient descent to get out of local minima, accelerate the descent, and cross the most dangerous saddle points.\n",
    "\n",
    "It has now been time and time improved upon, leading to the popular *Adam* algorithm.\n",
    "\n",
    "It looks as follows:\n",
    "```\n",
    "Given two parameters beta_1 and beta_2, and learning rate eta\n",
    "Start with:\n",
    "    theta := theta_0\n",
    "    m := 0 (first moment ~> mean)\n",
    "    v := 0 (second moment ~> variance)\n",
    "While no convergence observed:\n",
    "    Take a (mini/small/full)batch of the data, X\n",
    "    Set grad_new := gradient_oracle( theta , X )\n",
    "    Set m_new = beta_1 * m + (1-beta_1) * grad_new\n",
    "    Set v_new = beta_2 * v + (1-beta_2) * grad_new * grad_new\n",
    "    Correct biases in moment estimates:\n",
    "        Set m_hat = m_new / (1-beta_1)\n",
    "        Set v_hat = v_new / (1-beta_2)\n",
    "    Set theta_new := theta - eta * m_hat / square_root( v_hat )\n",
    "```\n",
    "**Implement this new algorithm for `function6`. Try to explain in your own words what the main ideas of this algorithm are, and comment on the hyper parameters $\\beta_1$ and $\\beta_2$.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
